# 方圆 安全分析
*经过一段时间的视频APP使用与测试,目前的结论如下*

## 短视频面临的安全问题

#### 1. 非法视频
问题视频主要是以**色情视频为主**,其他**恶意视频**为辅,
问题视频一旦过审,极有可能引起大范围传播,影响平台生态,甚至引发政策风险.

对于色情视频,上传者一般通过视频简介,**附加在视频中的文字和语音引导用户到某网站或微信号,并以此获利**
对于其他恶意视频(政治敏感,维权,暴恐...),上传者往往有明确的目标和动力,**不以上传之后的传播获利为主**
甚至再上传之前就已经收到了他人的资助.而且其他恶意视频的政策风险更为严峻.

基于cd人工审核团队的经验,非法视频中以**色情视频占了绝大多数**.

#### 2. 非法言论
明显恶意的言论,如政治敏感,讨论国家领导人,贩卖枪支弹药,招嫖色情,出售色情资源等
关键词明显,影响用户体验并具有政策风险,

#### 3. 不良评论
没有明显恶意的言论,多为微商,广告等消息.原则上不违反泛法律法规,但严重影响用户体验.
并且关健词与关键特征并不明显.例如,为了对抗屏蔽,关键词**微信**会会有多种变体:VX,薇♥,V信..(以同音词和emoji为主) 

#### 4. LBS带来的安全性问题
因为产品自带的LBS熟悉,容易单身女性等弱势群体造成安全性问题(参考滴滴相关事件)
目前只设置了匿名上传,提醒用户等相关功能. 如果在技术上混淆视频所属地理位置则失去了
LBS的属性,但是由于观看者强匿名性,又不能采取类似滴滴的措施.

## 应对手段

### 同类产品的应对方案

#### 非法/恶意文本
1. bilibili 关键词屏蔽

![2.png](https://upload-images.jianshu.io/upload_images/5617720-1809920464079e00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![bilibili 文本.png](https://upload-images.jianshu.io/upload_images/5617720-916345667958a11d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

2. 抖音 发送前关键词监测
![image.png](https://upload-images.jianshu.io/upload_images/5617720-42c58c716570ad77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


3. 微视 仅自己可见
![image.png](https://upload-images.jianshu.io/upload_images/5617720-3541ccf86bb07aa0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![image.png](https://upload-images.jianshu.io/upload_images/5617720-d3acf916f55e6fd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对比分析
- 屏蔽 : 即使对某些敏感词屏蔽也无法防止意义的表达,但是能够有效地规避风险.
- 发送前监测 : 实现简单,但无法应对一些突发事件. 敏感词库的及时填充也是一个需要考虑的问题.
- 仅自己可见 : 最大程度上的用户友好,但对于网页版来说可能会增加后台压力,但APP则不会有这个问题.

#### 色情/恶意视频
1. bilibili 人工审核
![image.png](https://upload-images.jianshu.io/upload_images/5617720-6d390d56a601c184.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![image.png](https://upload-images.jianshu.io/upload_images/5617720-36862449b92d0ebb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
(视频审核约需要3~5h,且会明确指出稿件不符合规范的时间点,且审核反馈是人工生成)

2. 抖音 推测是人工审核和算法审核结合
色情视频上传之后秒被封禁
敏感视频上传之后约1h后被封禁

3. 微视 全量人工审核 
![image.png](https://upload-images.jianshu.io/upload_images/5617720-e22038f34aeabfe3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#### 用户
三个视频APP新注册在发表了恶意言论和恶意视频之后,仅有抖音对用户执行了封禁处理
![image.png](https://upload-images.jianshu.io/upload_images/5617720-28cc51ce14337113.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### 技术手段

#### 文本
1. 关键词过滤
关键词的发现 | 分类 | 补充 | 更新&删除
文本匹配算法 | 单关键词 BMP,KMP... | 多关键词 Tree树 DFA 跳跃优化 空间优化 

2. 机器学习(nlp 文本分类)
预处理 | 分词 | 停用词 | 自定义词典
特征工程 | TF-IDF | one-hot | TextRank | Word2vec | LSA
分类器 | GBDT | 决策树 | SVM | 贝叶斯 | 逻辑回归 |  ....

3. 深度学习
对于机器学习来说,过大的文本可能会出现**数据稀疏和维度爆炸**的问题,当然可以通过PCA或者LDA解决
但是通过深度学习就可以避免这个问题
[CNN用于文本分类](https://zhuanlan.zhihu.com/p/34383508)
[深度学习文本分类在支付宝投诉文本模型上的应用](https://zhuanlan.zhihu.com/p/42236712)

目前的思路
对于目前的应用来说,采用 **文本通过审核之后展示** + **审核中仅自己可见** 的处理策略是比较符合状况的
对于审核既可以采用文本分类+关键词过滤的方式进行处理,不光完成审核的操作. 细致定性既可以进一步分类恶意文本,又为下一步的用户特征提供数据输入

#### 视频
视频 -> 图片

##### 色情视频
主动色情图片识别 | 皮肤检测算法 | 裸露程度监测 | 深度神经网络 NSFW | 深度神经网络 + 特征预处理		
图片指纹 | MD5 | 重整大小 + MD5

##### 其他恶意视频
相似图片检索 | 感知hash | 图片特征提取 | 颜色特征-方向梯度直方图 | 深度学习

基于深度学习的视频性质划分 Google : [youtube-8m](https://github.com/google/youtube-8m)  [inception](https://github.com/google/inception)

目前的思路
主动色情识别 + 图片指纹应对色情视频 , 相似图片检索 dhash + 多段hash索引 + sift特征匹配应对恶意视频
其次结合用户举报反馈,最终以人和审核作为保证. (机器审核只要露过了1个色情视频,和露过1w个色情视频是没有区别的.) 机器审核的目的在于初筛和为人工审核提速(目前微视的短视频仍是全量人工审核的,对于一个新APP来说,全量人工审核也是比较方便的实现策略)

 最终采用 **上传所有视频先过机器审核(色情识别,被动相似)** + **视频播放到一定数量开始必须进行人工审核**
 这里最好能有视频播放量分布的图

future :
基于文本、视频内容的视频上传者信息多分类器融合深度学习判别模型?


#### 用户
用户特征收集 | 用户性质判别模型(机器学习分类器)
用户特征数据越多越好 ,越全越好 | 用户关系链挖掘

目前的思路 收集用户数据 + 判定用户性质 + 结合策略实施打击

### 策略 & 如何确定策略
策略这个词其实是来了这边第一次了解到. 因为恶意与恶意还是有性质和严重程度的差别. 不能采用一刀切的手段
策略实际上应该是对应之前技术手段发现内容的处理方式与方法.

#### 如何确定策略?
- 目前整体数据
- 目前的产品定位
- more?

#### 还有什么可用的策略
- 博主精选评论
- 匿名上传
- 未审核内容仅自己可见
- 多少举报后才进行处理
- more?

### 需要解决的问题
LBS + 安全性的问题?
如果获取了真正的数据 该如何确定策略呢?

### 其它

策略实际上要结合一部分用户场景
针对新APP的场景确定审核策略(提高用户活跃程度,提高平台数据)
对于不同阶段的应用应该根据**核心需求**采取不同的安全策略